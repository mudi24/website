---
title: GPT和DeepSeek模型
date: 2025-02-08
readTime: 3 min read
category: 人工智能
---

## GPT 

![GPT模型的诞生和发展](/blogs/images/gpt_history.png)

### GPT-1 (1.1亿参数)

* Decode-only Transformer架构
* 预训练后针对特定任务微调

![GPT-1模型架构](/blogs/images/gpt1.png)

这张图展示了GPT-1模型（1.1亿参数）的核心架构和特点。它采用了Decoder-only的Transformer架构，包含12层标准的Transformer解码器结构。图的左侧展示了模型的基本组成：文本和位置嵌入层、多头自注意力机制、前馈网络和层归一化等组件。右侧展示了模型在预训练后如何通过微调来适应不同的下游任务，包括分类、蕴含关系判断、文本相似度计算和多项选择等任务。这种架构设计为后来的GPT系列模型奠定了基础。

### GPT-2 (15亿参数)

GPT-2 模型拥有了一个重要特性：自回归式的单词预测能力。每一步预测都基于之前的上下文，模型会给出多个可能的候选词，并最终选择最合适的词来继续生成。这种预测机制使得GPT-2能够生成连贯的文本，并且通过提示（prompt）的方式来完成各种无监督任务，这也是后来GPT系列模型的基础特性。

### GPT-3 (1750亿参数)

GPT-3 模型拥有了上下文学习能力，并且正式成为了大模型

> 上下文学习能力：通过少量示例就能理解任务并进行相应的推理，不需要专门的微调，这种能力也被称为"少样本学习"。

### CodeX

CodeX是一个基于GPT架构并在GitHub代码数据上微调的语言模型，专门用于代码生成和理解任务。从图中可以看出，它具有以下特点：

1. 代码数据训练：使用GitHub上的公开代码进行微调，使模型具备强大的代码理解和生成能力。
2. 推理与代码合成：能够从文档字符串（docstring）理解需求并生成相应代码。在HumanEval评估集上，CodeX解决了28.8%的问题，明显优于GPT-3（0%）和GPT-J（11.4%）。
3. 采样策略：通过重复采样策略（每个问题100个样本），模型的问题解决率可以提高到70.2%，显示了其在代码生成任务上的优秀表现。
4. 局限性：在处理长链操作和变量绑定操作的docstring时仍存在一定困难。

### WebGPT

WebGPT是OpenAI开发的一个专门用于网页浏览和信息检索的模型，GPT模型所有和网页相关的操作都是基于WebGPT实现的

### InstructGPT

InstructGPT是OpenAI开发的一个重要模型，它通过人类反馈强化学习（RLHF）来改进GPT-3的输出质量。其核心训练过程包括三个步骤：

1. 监督学习阶段：收集人类标注的高质量示范数据，用于初步微调GPT-3
2. 奖励建模阶段：训练一个奖励模型来评估输出质量，该模型基于人类对不同输出的偏好排序进行训练
3. 强化学习阶段：使用PPO算法基于奖励模型的反馈来优化模型策略
这种训练方法使InstructGPT能够更好地理解和执行人类指令，生成更符合人类偏好的输出，为后来的ChatGPT奠定了重要基础。

### ChatGPT

ChatGPT是基于InstructGPT技术开发的对话模型，其训练过程包含三个关键步骤：

1. 收集示范数据并训练监督策略：从数据集中采样提示，由标注者演示期望的输出行为，用这些数据对GPT-3.5进行监督学习微调。
2. 收集比较数据并训练奖励模型：对同一提示生成多个回答，由标注者对这些回答进行排序，用这些数据训练奖励模型来评估回答的质量。
3. 使用PPO强化学习算法优化策略：基于奖励模型的反馈，通过PPO算法不断优化模型的对话策略，使其生成更符合人类偏好的回答。
这种训练方法使ChatGPT能够生成更安全、更有帮助且更符合人类价值观的回答，显著提升了模型的对话能力和实用性。

### GPT-4

* 推理能力提升显著
* 支持多模态

### GPT-4o

* 作为原生多模态模型，支持统一处理和输出多种形式信息
* 拥有四个核心能力：跨模态理解、多模态生成、统一处理框架和综合推理能力

> 原生多模态模型是指模型在架构设计和训练阶段就直接支持多种模态（如文本、图像、音频、视频等）的输入和输出，而不是通过后期整合不同模态的单一模型。

### o系列模型

* 推理任务上能力大幅提升，也可以叫做推理模型
* 长思维链推理能力

> 推理任务是指需要模型进行复杂逻辑分析和推导的任务，比如数学问题求解、代码编程、科学问题分析等。

### o-series

O系列模型具有类似人类的"慢思考"过程。通过逐步推理的能力来处理复杂的推理任务。

## DeepSeek

![DeepSeek模型发展历程](/blogs/images/deepseek_history.png)

### 训练框架

DeepSeek采用了HAI-LLM训练框架（发布于2023年6月），这是一个支持多种并行策略的大规模深度学习训练框架。该框架具有以下特点：

* 支持大规模深度学习训练，能够高效处理海量数据
* 实现了多种并行训练策略，提高训练效率
* DeepSeek的三代主力模型均基于此框架完成训练

### 数据准备

DeepSeek在数据准备方面进行了全面的工作：

1. **大规模网络数据处理**
   * V1和Math技术报告详细说明了对Common Crawl数据的清洗过程
   * 建立了超大规模数据处理能力
 
> Common Crawl是一个非营利组织维护的大规模网页数据集，它通过网络爬虫收集公开的网页内容，并将这些数据免费提供给研究人员和开发者使用。在大语言模型训练中，Common Crawl是一个重要的数据来源，比如GPT-3和DeepSeek等模型都使用了经过清洗的Common Crawl数据。
> 
1. **代码数据收集**
   * Coder技术报告展示了大量代码数据的收集工作
   * 为模型提供了丰富的编程知识基础

2. **数学数据积累**
   * Math技术报告重点关注数学数据的收集和清洗
   * 强化了模型的数学推理能力

3. **多模态数据整合**
   * VL技术报告完成了多模态和图片数据的收集
   * 扩展了模型的多模态理解和生成能力

### DeepSeek-V3

* 671B参数 (37B激活)，14.8T训练数据
* 基于V2的MoE架构，引入了MTP和新的复杂均衡损失
* 对于训练效率进行了极致优化，共使用 2.788M H800 GPU时

#### 核心架构解析

1. DeepSeekMoE架构：
- 基础的Transformer Block结构，包含前馈网络、RMSNorm和注意力机制
- 采用了Multi-Head Latent Attention机制来提升效率
- 引入了专家路由系统，包括路由专家和共享专家的设计

2. MTP训练方法）：
- 主模型和多个MTP模块共享底层组件
- 使用Cross-Entropy Loss进行多任务训练
- 通过线性投影和RMSNorm进行特征转换
- 多个MTP模块串联来提升模型的整体预测能力

这些创新使DeepSeek-V3在各项任务上都取得了显著的性能提升，特别是在推理能力和训练效率方面的优化尤为突出。

### DeepSeek-R1

DeepSeek-R1是基于DeepSeek V3-Base模型开发的强化推理模型，其技术演变过程包含四个关键阶段：

1. **冷启动SFT（用于合成微调数据）**
   * 初始阶段使用SFT（Supervised Fine-Tuning）技术
   * 通过合成数据进行模型的初步训练

2. **推理RL**
   * 使用强化学习技术增强模型的推理能力
   * 优化模型的决策过程

3. **RFT&SFT（Base模型微调）**
   * 对Base模型进行进一步的微调优化
   * 结合RFT（Reinforcement Fine-Tuning）和SFT技术

4. **全场景RL（SFT模型RL）**
   * 在SFT模型基础上应用强化学习
   * 提升模型在各种场景下的表现

从训练过程的性能指标来看：

* AIME准确率显著提升：从初始的约20%提升到最终的70-80%水平

> AIME (American Invitational Mathematics Examination) 是美国数学邀请赛，这是一个高水平的数学竞赛。在DeepSeek模型的评测中，AIME被用作衡量模型数学推理能力的重要指标之一。

* 响应长度逐步增加：随着训练步骤的推进，模型的平均响应长度稳步提升
* 训练效果稳定：曲线显示模型性能持续改善，且波动较小

这种多阶段训练方法使DeepSeek-R1在推理能力方面取得了显著进展，为后续模型的发展提供了重要的技术参考。

### 为什么DeepSeek会引起世界关注

* 打破了OpenAI闭源产品的领先时效性

> 国内追赶GPT-4的时间很长，然而复现o1模型的时间大大缩短

* 达到了与OpenAI现有API性能可比的水平
 
* 中国具备实现世界最前沿大模型的核心技术
* 模型开源、技术开放
