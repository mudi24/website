---
title: 大语言模型技术基础
date: 2025-02-07
readTime: 2 min read
category: 人工智能
---

### 预训练
大模型预训练主要包含五个关键步骤：

1. 数据准备：构建高质量语料库，进行清洗和标准化处理，建立高效的数据加载流水线。
2. 模型设计：选择合适的基础架构（如Transformer），确定模型规模，实现并行训练架构。
3. 训练优化：采用混合精度训练，实现梯度累积和检查点机制，优化内存使用和通信效率。
4. 分布式训练：搭建大规模分布式训练系统，实现模型并行和数据并行，确保训练稳定性。
5. 后处理优化：进行模型压缩和量化，评估模型性能，部署和持续优化。

> 数据质量和数据数量对于大模型的训练至关重要，而保证数据质量的关键在于数据标注和数据清洗。

> 无论是预训练还是后训练，都需要大量的计算资源和时间，建议从小规模实验开始，逐步扩大训练规模。

### 后训练

后训练主要是指在现有基座模型基础上，通过微调、指令微调、人类对齐等方式，将基座模型适配到具体应用场景，针对特定领域进行微调，以适应特定任务的需求。如医疗、金融、法律、教育等。

#### 指令微调

指令微调（Instruction Tuning）是后训练阶段的重要环节。主要包含两个核心目标：

1. 使用输入与输出配对的指令数据对模型进行微调，提升模型理解和执行指令的能力。
2. 通过问答形式提升模型完成任务的能力。

通过指令微调，可以让模型更好地理解人类意图，提供更准确的回应。

#### 人类对齐

大语言模型的后训练（Post-Training）过程中的人类对齐（Human Alignment）方法，主要包含三种技术路线：

1. 监督微调：使用人类标注的示例数据对预训练模型进行训练，通过人类反馈来改进模型输出质量。
2. 奖励模型训练：基于人类排序的偏好数据，训练一个奖励模型来评估和指导语言模型的输出。
3. 强化学习微调：使用强化学习算法（RLHF）来优化模型，通过人类反馈作为奖励信号，让模型输出更符合人类期望。

这三种方法共同目标是将大语言模型与人类的期望、需求和价值观对齐，使模型输出更安全、更有用、更符合伦理。

## 扩展定律

### Loss

loss（损失函数）是衡量模型预测效果的重要指标，有以下三个特点：

- Loss 表示模型预测结果与真实结果之间的差距
- 值越小表示模型预测越准确
- 训练过程就是不断最小化 loss 的过程

### KM扩展定律

![KM扩展定律](/blogs/images/km_expansion_law.png)

这张图展示了 OpenAI 团队提出的 KM (Kaplan-Moss) 扩展定律，主要描述了大语言模型的性能与三个关键因素之间的关系：

1. 模型规模定律 L(N)：
- N 代表模型参数量
- Nc 是临界参数量，约为 8.8×10¹³
- αN ≈ 0.076，表示缩放指数
- 公式：$L(N) = (N_c/N)^{\alpha_N}$

2. 数据规模定律 L(D)：
- D 代表训练数据量（token数）
- Dc 是临界数据量，约为 5.4×10¹³
- αD ≈ 0.095
- 公式：$L(D) = (D_c/D)^{\alpha_D}$

3. 计算规模定律 L(C)：
- C 代表计算量
- Cc 是临界计算量，约为 3.1×10⁸
- αC ≈ 0.050
- 公式：$L(C) = (C_c/C)^{\alpha_C}$

右侧图表展示了不同规模模型的 loss 随训练数据量增加的变化趋势：
- 横轴：训练数据量（tokens）
- 纵轴：模型 loss
- 不同颜色的线代表不同参数量的模型（从 393.2K 到 708M）
- 可以观察到：
  1. loss 随数据量增加而降低
  2. 参数量越大的模型，最终能达到的 loss 越低
  3. 曲线呈现出幂律衰减特征

这个定律对于理解和预测大语言模型的性能提升非常重要，也为模型设计和训练资源分配提供了理论指导。

### Chinchilla扩展定律

![Chinchilla扩展定律](/blogs/images/chinchilla_expansion_law.png)

这张图展示了 DeepMind 团队在2022年提出的 Chinchilla 扩展定律，主要描述了大语言模型训练的最优资源分配策略：

1. 损失函数公式：
$$L(N, D) = E + \frac{A}{N^\alpha} + \frac{B}{D^\beta}$$
其中：
- N: 模型参数量
- D: 训练数据量
- E, A, B, α, β 是常数
- 这个公式描述了模型性能（Loss）与参数量和数据量的关系

2. 最优配置公式：
$$N_{opt}(C) = G(C/6)^a$$
$$D_{opt}(C) = G^{-1}(C/6)^b$$
其中：
- C: 计算资源（FLOPs）
- N_opt: 最优参数量
- D_opt: 最优数据量
- G, a, b 是常数


3. 右侧图表展示：
- 横轴：计算量（FLOPs）
- 纵轴：模型参数量
- 不同颜色的线代表不同的训练方法
- 星形标记代表几个知名模型：
  - Chinchilla (70B)
  - Gopher (280B)
  - GPT-3 (175B)
  - Megatron-Turing NLG (530B)

核心发现：
1. 传统模型往往参数量过大而训练数据不足
2. 在固定计算预算下，使用较小的模型和更多的训练数据通常能获得更好的性能
3. 最优的参数量和训练数据量应该保持大约 1:20 的比例

这个定律对于大语言模型的高效训练提供了重要指导，帮助在有限计算资源下获得最佳训练效果。

### 使用扩展定律中遇到的问题

模型损失可以分为可约损失和不可约损失两部分，其中可约损失是真实分布和模型分布之间的KL散度，可以通过优化来减少；而不可约损失是真实数据分布的熵，无法通过优化来减少。

随着模型参数和数据量的扩展，模型性能增益将逐渐减小。
目前由于开放数据接近枯竭，这种扩展定律的持续推进面临挑战。

#### 可预测的扩展（Predictable Scaling）

> 使用小模型性能去预估大模型的性能，或帮助超参数选择
> 训练过程中使用模型早期性能来预估后续性能

![可预测的扩展](/blogs/images/predictable_scaling.png)

这张图展示了"可预测的扩展"(Predictable Scaling)概念，主要来自DeepSeek LLM的研究，发表于2024年的Arxiv论文。图中内容主要包括：

1. 标题与概念：
   - "可预测的扩展"指的是使用小模型性能预测大模型性能，或在训练过程中使用早期性能预测后续性能的方法

2. 左侧图表(a)：批量大小扩展曲线
   - 横轴：非嵌入训练FLOPs（计算量）
   - 纵轴：最优批量大小（Tokens）
   - 显示了随着计算资源增加，最优批量大小的增长趋势
   - 标记了两个模型：7B MHA 2T Token和67B GQA 2T Token
   - 灰色区域表示预测的置信区间

3. 右侧图表(b)：学习率扩展曲线
   - 横轴：非嵌入训练FLOPs（计算量）
   - 纵轴：最优学习率
   - 显示了随着计算资源增加，最优学习率的下降趋势
   - 同样标记了两个模型数据点

这项研究的主要价值在于：
1. 提供了一种预测大模型训练超参数的方法
2. 可以通过小模型实验结果推断大模型的最优配置
3. 帮助研究人员在不进行昂贵的大规模实验的情况下，优化大模型训练策略

这种扩展规律对于大语言模型的高效训练非常重要，可以节省大量计算资源和时间。


## 涌现能力

![涌现能力](/blogs/images/emergent_ability.png)

这张图展示了关于大语言模型涌现能力(Emergent Abilities)的研究，来自NIPS 2023的论文"Are Emergent Abilities of Large Language Models a Mirage?"。图中包含六个子图(A-F)，对比了模型在不同任务上的表现：

左侧(C、D)展示了"涌现能力"现象：
- C图：随着模型参数增加，在特定任务上的准确率呈现非线性增长，小模型几乎无能力，大模型突然表现优异
- D图：多项选择题任务上也表现出类似的不连续跃升

右侧(E、F)展示了"无涌现能力"的对照组：
- E图：模型在某些任务上表现出线性进步，没有突然的性能跃升
- F图：另一个任务上也表现出连续的性能提升

中间(A、B)提供了理论解释：
- A图：展示了交叉熵损失随模型参数增加而下降的趋势
- B图：给出了单个token正确概率与交叉熵损失的数学关系

这项研究的核心观点是：所谓的"涌现能力"可能只是一种观察视角的错觉。当我们用不同的评估方式(如非线性评分vs线性评分)来衡量模型性能时，同样的底层能力提升可能会呈现出不同的表现形式。

这对理解大语言模型的能力进化有重要意义，提示我们需要更谨慎地解读模型性能的突变现象。

### 涌现能力的体现

* 指令遵循
* 上下文学习
* 逐步推理（step-by-step reasoning）
  

扩展规律可以理解为是一种较为平滑的多任务损失平均(LM loss)
涌现能力则是非平滑的、某种特定能力或任务的性能跃升(Task loss)

![涌现能力与扩展定律](/blogs/images/expansion_vs_emergent.png)

这张图展示了涌现能力与扩展定律之间的关系，主要对比了两种不同的模型性能增长模式：

左侧展示了扩展定律(Scaling Law)的特点：
- 描述了一种可预测的(predictable)增长模式
- 但这种增长具有收益递减(diminishing return)特性
- 可以理解为一种相对平滑的多任务损失平均(LM loss)
- 图表显示从0.1B到100B参数的模型性能呈现平缓的增长曲线
- 这种模式大约在2020-2021中被广泛观察到

右侧展示了涌现能力(Emergent Ability)的特点：
- 超越了常规扩展定律的预测
- 增长是不可预测的(unpredictable)但非常有价值(profitable)
- 表现为非平滑的、某种特定能力或任务的性能跃升(Task loss)
- 图表显示在约10B参数附近出现明显的相变(Phase change)，性能突然大幅提升
- 这种现象从2022年初开始被观察到

中间的结论指出：模型规模扩展是强大能力涌现的关键(Model scaling is the key to the emergence of strong abilities)

这张图很好地解释了为什么大语言模型在达到一定规模后会表现出意想不到的新能力，而这些能力无法从小模型的表现中简单外推预测。

## 总结

本文详细介绍了大语言模型的三个核心技术基础：训练流程、扩展定律和涌现能力。

在训练流程方面，大语言模型采用"预训练+后训练"的范式。预训练阶段注重通过高质量数据和优化的训练策略构建基础能力，后训练阶段则通过指令微调等方法提升模型的实用性和安全性。

在扩展定律方面，KM定律揭示了模型性能与参数量、数据量、计算量之间的定量关系，而Chinchilla定律则进一步优化了资源分配策略，指出参数量与训练数据量应保持1:20 的比例。这些定律为大模型的高效训练提供了重要指导。

在涌现能力方面，研究表明大语言模型在达到一定规模后会表现出意想不到的新能力。这种涌现能力可能源于底层能力的累积，也可能受到评估方式的影响。理解涌现能力对于模型设计和评估具有重要意义。

这些技术基础的深入理解和应用，对于推动大语言模型的发展和应用至关重要。
